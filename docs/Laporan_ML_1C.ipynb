{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laporan Tugas Besar 1 Bagian C IF3270 Pembelajaran Mesin\n",
    "oleh Ignatius Timothy Manullang / 13517044, Fata Nugraha /  13517109, Edward Alexander Jaya /  13517115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penjelasan Implementasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library yang dibutuhkan program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier # neural network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut merupakan fungsi sigmoid berdasarkan rumus\n",
    "![image.png](attachment:image.png)\n",
    "yang akan digunakan untuk perhitungan sigmoid di perceptron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Perceptron\n",
    "\n",
    "Dalam kelas perceptron, terdapat beberapa parameter, yaitu\n",
    "* data : list of data input yang akan diproses oleh perceptron\n",
    "* weight : list of weight dari seluruh data input\n",
    "* delta weight : list of delta weight dari seluruh data input\n",
    "* rate : learning rate dari perceptron\n",
    "\n",
    "init digunakan untuk menginisialisasi perceptron dengan data kosong, weight random, delta weight 0 dan learning rate sesuai yang diinput\n",
    "\n",
    "input_data digunakan untuk menginput data ke perceptron \n",
    "\n",
    "calc_sigmoid digunakan pada proses feed forward untuk mengkalkulasi net dari suatu layer neuron, lalu berdasarkan net itu, mengkalkulasi output dari layer neuron tersebut dengan fungsi sigmoid\n",
    "\n",
    "calc_delta digunakan saat backpropagation untuk menghitung delta dari suatu data berdasarkan rumus\n",
    "![calc_delta](images/delta_hidden.png)\n",
    "\n",
    "update_delta_weight saat backpropagation digunakan untuk memperbarui delta weight dari suatu data berdasarkan rumus\n",
    "![update_delta_weight](images/delta_weight.png)\n",
    "\n",
    "update_weight digunakan saat akhir batch untuk memperbarui weight dari suatu data berdasarkan rumus\n",
    "![update_weight](images/weight.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, rate, input_length):\n",
    "        self.data = []\n",
    "        self.weight = []\n",
    "        self.delta_weight = []\n",
    "        self.rate = rate\n",
    "\n",
    "        random_matrix = np.random.randn(1, input_length) * np.sqrt(1 / input_length)\n",
    "        for rand_array in random_matrix:\n",
    "            for rand_num in rand_array:\n",
    "                self.weight.append(rand_num)\n",
    "\n",
    "        # print(self.weight)\n",
    "\n",
    "        for inp in range(input_length):\n",
    "            self.delta_weight.append(0)\n",
    "\n",
    "\n",
    "    def input_data(self, data):\n",
    "        self.data = []\n",
    "        for datum in data:\n",
    "            self.data.append(datum)\n",
    "\n",
    "    def calc_sigmoid(self):\n",
    "        jumlah = 0\n",
    "        for i in range(len(self.data)):\n",
    "            jumlah += self.data[i] * self.weight[i]\n",
    "        self.output = sigmoid(jumlah)\n",
    "\n",
    "    #for backprop\n",
    "    def calc_delta(self, multiplier):\n",
    "        self.delta = self.output * (1-self.output) * multiplier\n",
    "\n",
    "    def update_delta_weight(self):\n",
    "        for i in range(len(self.delta_weight)):\n",
    "            self.delta_weight[i] += self.rate * self.delta * self.data[i]\n",
    "\n",
    "    # End of batch-size\n",
    "    def update_weight(self):\n",
    "        for i in range(len(self.weight)):\n",
    "            self.weight[i] += self.delta_weight[i]\n",
    "            self.delta_weight[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class myMLP\n",
    "\n",
    "Dalam kelas myMLP, terdapat beberapa atribut yaitu\n",
    "* layers : list of data in a layer\n",
    "\n",
    "* hidden_layer_sizes : list dari jumlah hidden layer yang ada pada 1 layer\n",
    "* learning_rate : learning rate dari MLP\n",
    "* max_iter : jumlah iterasi maksimum dari MLP\n",
    "* error_treshold : batas error untuk mengakhiri proses MLP\n",
    "* batch_size : ukuran batch sebelum MLP mengupdate weight dari data\n",
    "\n",
    "fit digunakan untuk melakukan proses MLP berdasarkan input data dan target. Mulai dari inisialisasi data input sampai akhir dari \n",
    "\n",
    "update_all_weight digunakan untuk update semua weight dari seluruh perceptron dalam 1 layer\n",
    "\n",
    "calculate_error digunakan untuk mengkalkulasi error berdasarkan squared error function\n",
    "![calculate_error](images/calculate_error.png)\n",
    "\n",
    "initialize_perceptrons_in_layer digunakan untuk memasukkan perceptron ke dalam layer berdasarkan input jumlah perceptron dan jumlah input\n",
    "\n",
    "feed_forward digunakan untuk mengeksekusi feed forward. feed_forward akan mengkalkulasi net dan output dari suatu input data untuk satu layer, lalu memasukkan output sebagai input data untuk layer selanjutnya, dan mengulanginya untuk semua layer.\n",
    "\n",
    "backward_prop digunakan untuk mengeksekusi backward propagation.\n",
    "Untuk layer terakhir\n",
    "1. Pertama, backward_prop akan mengecek jika hasil kelas output sama dengan target, jika sama, maka valuenya 1, jika beda, maka valuenya 0. \n",
    "2. Kedua, backward_prop akan menghitung diff, yaitu perbedaaan antara output dan target. \n",
    "3. Ketiga, backward_prop akan menghitung delta dari satu perceptron pada layer terakhir. \n",
    "4. Keempat, backward_prop akan memperbarui delta_weight dari satu perceptron pada layer terakhir. \n",
    "5. Kelima, backward_prop akan menambahkan total error berdasarkan error dari satu perceptron pada layer terakhir. Proses ini diulangi untuk semua perceptron yang ada pada layer terakhir.\n",
    "Untuk hidden layer\n",
    "1. backward_prop akan mengkalkulasi diff, yaitu delta dikali weight, untuk satu perceptron di satu layer.\n",
    "2. backward_prop akan menghitung delta berdasarkan diff, untuk satu perceptron di satu layer.\n",
    "3. backward_prop akan menghitung delta weight, untuk satu perceptron di satu layer.\n",
    "4. backward prop akan mengulangi proses 1-3 untuk semua perceptron dalam satu layer.\n",
    "5. Lalu, backward_prop akan mengulangi proses 1-4 untuk semua layer yang ada kecuali yang terakhir (karena layer yang terakhir adalah layer output)\n",
    "\n",
    "predict digunakan untuk memprediksi nilai output dari data input\n",
    "\n",
    "show_model digunakan untuk menampilkan hasil dari proses MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMLP:\n",
    "\n",
    "    def __init__(self, hidden_layer_sizes=[2, 3], learning_rate=0.001, max_iter=200, error_treshold=0.0001, batch_size=32):\n",
    "        # Attributes\n",
    "        self.layers = []\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.error_treshold = error_treshold\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    def fit(self, data_inputs, target):\n",
    "        self.data_inputs = data_inputs\n",
    "        self.target = target\n",
    "        self.classes = self.target.unique()\n",
    "\n",
    "        try:\n",
    "            #\n",
    "            number_of_inputs_from_previous_layer = len(self.data_inputs.columns)\n",
    "            # Initialize perceptrons in the hidden layers (from index 1)\n",
    "            for layer_idx in range(len(self.hidden_layer_sizes)):\n",
    "                # hidden_layer = Array of perceptrons\n",
    "                number_of_perceptrons_current_layer = self.hidden_layer_sizes[layer_idx]\n",
    "                hidden_layer = self.initialize_perceptrons_in_layer(number_of_perceptrons_current_layer, number_of_inputs_from_previous_layer)\n",
    "                number_of_inputs_from_previous_layer = self.hidden_layer_sizes[layer_idx]\n",
    "                self.layers.append(hidden_layer)\n",
    "\n",
    "            # Construct last (output) layer of perceptrons\n",
    "            number_of_perceptrons_last_layer = len(self.target.unique())\n",
    "            number_of_inputs_from_previous_layer = self.hidden_layer_sizes[-1]\n",
    "\n",
    "            output_layer = self.initialize_perceptrons_in_layer(number_of_perceptrons_last_layer, number_of_inputs_from_previous_layer)\n",
    "            self.layers.append(output_layer)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # Construct last (output) layer of perceptrons\n",
    "            number_of_perceptrons_last_layer = len(self.target.unique())\n",
    "            number_of_inputs_from_previous_layer = len(self.data_inputs.columns)\n",
    "            output_layer = self.initialize_perceptrons_in_layer(number_of_perceptrons_last_layer, number_of_inputs_from_previous_layer)\n",
    "            self.layers.append(output_layer)\n",
    "\n",
    "        # Start feed forward and backward prop\n",
    "        number_of_rows = len(data_inputs)\n",
    "        for iteration in range(self.max_iter):\n",
    "            error_total = 0\n",
    "            for row in range(number_of_rows):\n",
    "                # print(\"row\")\n",
    "                # print(row)\n",
    "                self.feed_forward(row)\n",
    "\n",
    "                # Do backward prop then get error\n",
    "                error = self.backward_prop(row)\n",
    "                error_total += error\n",
    "\n",
    "                if (row % self.batch_size == 0):\n",
    "                    self.update_all_weights()\n",
    "\n",
    "            self.update_all_weights()\n",
    "\n",
    "            if (error_total < self.error_treshold):\n",
    "                break\n",
    "\n",
    "    def update_all_weights(self):\n",
    "        for layer in self.layers:\n",
    "            for perceptron in layer:\n",
    "                perceptron.update_weight()\n",
    "\n",
    "    def calculate_error(self, diff):\n",
    "        return 0.5 * (diff ** 2)\n",
    "\n",
    "    def initialize_perceptrons_in_layer (self, number_of_perceptrons, number_of_inputs):\n",
    "        layer = []\n",
    "        for idx_perceptron in range(number_of_perceptrons):\n",
    "            layer.append(Perceptron(self.learning_rate, number_of_inputs+1))\n",
    "        return layer\n",
    "\n",
    "    def feed_forward(self, row):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        # Initial inputs\n",
    "        for column in self.data_inputs.columns:\n",
    "            inputs.append(self.data_inputs[column][row])\n",
    "        inputs.append(1)\n",
    "\n",
    "        for layer_idx in range(len(self.layers)):\n",
    "            outputs.clear()\n",
    "            for perceptron in self.layers[layer_idx]:\n",
    "                perceptron.input_data(inputs)\n",
    "                perceptron.calc_sigmoid()\n",
    "                outputs.append(perceptron.output)\n",
    "\n",
    "            inputs.clear()\n",
    "            for output_data in outputs:\n",
    "                inputs.append(output_data)\n",
    "\n",
    "            inputs.append(1)\n",
    "\n",
    "    def backward_prop(self, row):\n",
    "        # Last layer\n",
    "        total_error = 0\n",
    "        for i in range(len(self.layers[-1])):\n",
    "            perceptron = self.layers[-1][i]\n",
    "            # Calculate diff (multiplier):\n",
    "            if self.classes[i] == self.target[row]:\n",
    "                result = 1\n",
    "            else:\n",
    "                result = 0\n",
    "            diff = result - perceptron.output\n",
    "            perceptron.calc_delta(diff)\n",
    "            perceptron.update_delta_weight()\n",
    "            total_error += self.calculate_error(diff)\n",
    "\n",
    "        # Hidden layers\n",
    "        for layer_idx in range(len(self.layers)-1): #banyaknya layer di layers, kecuali output layer\n",
    "            layer_size = len(self.layers[-layer_idx-2]) #banyaknya perceptron di layer itu\n",
    "            for perc_idx in range(layer_size): #untuk setiap perceptron di layer itu\n",
    "                diff = 0\n",
    "                for next_perceptron in self.layers[-layer_idx-1]:\n",
    "\n",
    "                    diff += next_perceptron.delta * next_perceptron.weight[perc_idx]\n",
    "                self.layers[-layer_idx-2][perc_idx].calc_delta(diff)\n",
    "                self.layers[-layer_idx-2][perc_idx].update_delta_weight()\n",
    "\n",
    "        return total_error\n",
    "\n",
    "    def predict(self, data_inputs):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        predictions = []\n",
    "        for row in range(len(data_inputs)):\n",
    "            inputs.clear()\n",
    "            outputs.clear()\n",
    "            # Initial inputs\n",
    "            for column in data_inputs.columns:\n",
    "                inputs.append(data_inputs[column][row])\n",
    "            inputs.append(1)\n",
    "\n",
    "            for layer_idx in range(len(self.layers)):\n",
    "                outputs.clear()\n",
    "                for perceptron in self.layers[layer_idx]:\n",
    "                    perceptron.input_data(inputs)\n",
    "                    perceptron.calc_sigmoid()\n",
    "                    outputs.append(perceptron.output)\n",
    "                inputs.clear()\n",
    "                for output in outputs:\n",
    "                    inputs.append(output)\n",
    "                inputs.append(1)\n",
    "            idx = outputs.index(max(outputs))\n",
    "            predictions.append(self.classes[idx])\n",
    "        return predictions\n",
    "\n",
    "    def show_model(self):\n",
    "        for layer_idx in range(len(self.layers)):\n",
    "            for perceptron_idx in range(len(self.layers[layer_idx])):\n",
    "                for weight_idx in range(len(self.layers[layer_idx][perceptron_idx].weight)):\n",
    "                    print(\"Weight \", weight_idx, \"-\", \"[\", layer_idx, \"][\", perceptron_idx, \"]: \", self.layers[layer_idx][perceptron_idx].weight[weight_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Eksekusi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-230b4dc5a920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'species'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model (weights):\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1474e6b7aece>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data_inputs, target)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "mlp = myMLP(max_iter = 4001, hidden_layer_sizes=[100])\n",
    "inputs = data.drop('species', axis = 1)\n",
    "target = data[['species']]\n",
    "\n",
    "mlp.fit(inputs,target)\n",
    "\n",
    "print(\"Model (weights):\")\n",
    "mlp.show_model()\n",
    "\n",
    "#training\n",
    "df = pd.concat([inputs, target], axis=1)\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "\n",
    "trainX = train[['sepal_length','sepal_width','petal_length','petal_width']] # taking the training data features\n",
    "trainY = train.species # output of our training data\n",
    "testX = test[['sepal_length','sepal_width','petal_length','petal_width']] # taking test data features\n",
    "testY = test.species   # output value of test data\n",
    "\n",
    "trainX = trainX.reset_index(drop=True)\n",
    "trainY = trainY.reset_index(drop=True)\n",
    "testX = testX.reset_index(drop=True)\n",
    "testY = testY.reset_index(drop=True)\n",
    "\n",
    "mlp2 = myMLP(max_iter = 4001, hidden_layer_sizes=[100])\n",
    "mlp2.fit(trainX, trainY)\n",
    "prediction = mlp2.predict(testX)\n",
    "val = 0\n",
    "for i in range(len(prediction)):\n",
    "\tif prediction[i] == testY.values[i]:\n",
    "\t\tval += 1\n",
    "print(\"Tested : \" + str(len(prediction)))\n",
    "print(\"True : \" + str(val))\n",
    "print(\"Accuracy : \" + str(val/len(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perbandingan dengan hasil MLP sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"iris.csv\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[['species']].replace(['Iris-setosa','Iris-versicolor','Iris-virginica'],[0,1,2])\n",
    "target.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = data.drop('species', axis = 1)\n",
    "df = pd.concat([newData, target], axis=1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3)\n",
    "trainX = train[['sepal_length','sepal_width','petal_length','petal_width']] # taking the training data features\n",
    "trainY=train.species# output of our training data\n",
    "testX= test[['sepal_length','sepal_width','petal_length','petal_width']] # taking test data features\n",
    "testY =test.species   #output value of test data\n",
    "trainX.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = MLPClassifier(solver='sgd', batch_size=32, alpha=0, momentum=0, nesterovs_momentum=False, activation='logistic', max_iter=4001, hidden_layer_sizes=(100))\n",
    "\n",
    "clf1.fit(newData,target)\n",
    "print(\"Model (weights)\")\n",
    "print(clf1.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = MLPClassifier(solver='sgd', batch_size=32, alpha=0, momentum=0, nesterovs_momentum=False, activation='logistic', max_iter=4001, hidden_layer_sizes=(100))\n",
    "clf2.fit(trainX, trainY)\n",
    "\n",
    "prediction = clf2.predict(testX)\n",
    "print(\"Prediction\")\n",
    "print(prediction)\n",
    "\n",
    "print(\"Values of testY\")\n",
    "print(testY.values)\n",
    "\n",
    "print('The accuracy of the Multi-layer Perceptron is:',metrics.accuracy_score(prediction,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembagian tugas setiap anggota kelompok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NIM | Nama | Tugas |\n",
    "| -- | -- | -- |\n",
    "| 13517044 | Ignatius Timothy Manullang | laporan, testing, analisis  |\n",
    "| 13517109 | Fata Nugraha | class Perceptron, debug class myMLP |\n",
    "| 13517115 | Edward Alexander Jaya | basic class myMLP |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "e5f61757-c4c4-45e0-a0f7-f2e62efcab51"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
